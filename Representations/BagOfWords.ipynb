{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag Of Words (BoW) Model from Scratch with step-by-step explanation\n",
    "\n",
    "**Core Idea: Count the Number of times each word appears in a document**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Sample Corpus & Preprocessing (Tokenization and Vocab Creation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Large corpus for testing BoW:\n",
    "corpus = [\n",
    "    \"Natural language processing (NLP) is a field of artificial intelligence that focuses on the interaction between computers and humans through natural language.\",\n",
    "    \"The goal of NLP is to enable computers to understand, interpret, and generate human language in a way that is both meaningful and useful.\",\n",
    "    \"Applications of NLP include language translation, sentiment analysis, speech recognition, and chatbot systems.\",\n",
    "    \"Machine learning and deep learning techniques are commonly used in NLP to model and solve complex language tasks.\",\n",
    "    \"Large datasets and pre-trained models like BERT and GPT have significantly advanced the state of the art in NLP research.\",\n",
    "    \"Tokenization, stemming, lemmatization, and part-of-speech tagging are fundamental preprocessing steps in NLP.\",\n",
    "    \"Text classification is a popular task in NLP that involves categorizing text into predefined labels based on its content.\",\n",
    "    \"Named entity recognition (NER) is the process of identifying proper names in text, such as people, organizations, and locations.\",\n",
    "    \"Syntax and semantics are essential aspects of language understanding in NLP systems.\",\n",
    "    \"Developing efficient, scalable, and interpretable NLP models is an active area of research and industry practice.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['natural', 'language', 'processing', '(nlp)', 'is', 'a', 'field', 'of', 'artificial', 'intelligence', 'that', 'focuses', 'on', 'the', 'interaction', 'between', 'computers', 'and', 'humans', 'through', 'natural', 'language.'], ['the', 'goal', 'of', 'nlp', 'is', 'to', 'enable', 'computers', 'to', 'understand,', 'interpret,', 'and', 'generate', 'human', 'language', 'in', 'a', 'way', 'that', 'is', 'both', 'meaningful', 'and', 'useful.'], ['applications', 'of', 'nlp', 'include', 'language', 'translation,', 'sentiment', 'analysis,', 'speech', 'recognition,', 'and', 'chatbot', 'systems.'], ['machine', 'learning', 'and', 'deep', 'learning', 'techniques', 'are', 'commonly', 'used', 'in', 'nlp', 'to', 'model', 'and', 'solve', 'complex', 'language', 'tasks.'], ['large', 'datasets', 'and', 'pre-trained', 'models', 'like', 'bert', 'and', 'gpt', 'have', 'significantly', 'advanced', 'the', 'state', 'of', 'the', 'art', 'in', 'nlp', 'research.'], ['tokenization,', 'stemming,', 'lemmatization,', 'and', 'part-of-speech', 'tagging', 'are', 'fundamental', 'preprocessing', 'steps', 'in', 'nlp.'], ['text', 'classification', 'is', 'a', 'popular', 'task', 'in', 'nlp', 'that', 'involves', 'categorizing', 'text', 'into', 'predefined', 'labels', 'based', 'on', 'its', 'content.'], ['named', 'entity', 'recognition', '(ner)', 'is', 'the', 'process', 'of', 'identifying', 'proper', 'names', 'in', 'text,', 'such', 'as', 'people,', 'organizations,', 'and', 'locations.'], ['syntax', 'and', 'semantics', 'are', 'essential', 'aspects', 'of', 'language', 'understanding', 'in', 'nlp', 'systems.'], ['developing', 'efficient,', 'scalable,', 'and', 'interpretable', 'nlp', 'models', 'is', 'an', 'active', 'area', 'of', 'research', 'and', 'industry', 'practice.']]\n"
     ]
    }
   ],
   "source": [
    "# 2, Preprocessing: Tokenization and Vocabulary Building\n",
    "\n",
    "def tokenize(sent: str) -> List[str]:\n",
    "    return sent.lower().split()\n",
    "\n",
    "# Tokenize the corpus\n",
    "tokenized_corpus = [tokenize(sent) for sent in corpus]\n",
    "#print(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize all sentences:\n",
    "tokenized_corpus = [tokenize(sent) for sent in corpus]\n",
    "\n",
    "# Flatten and get unique words:\n",
    "all_words = [word for sent in tokenized_corpus for word in sent]\n",
    "vocab = sorted(set(all_words))\n",
    "vocab_size = len(vocab)\n",
    "word2idx = {word: idx for idx, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Bag of Words Encoding\n",
    "\n",
    "**For each Sentences count word frequencies and store in a fixed-size vector**\n",
    "\n",
    ">$$ \\text{BoW}_{i,j} = \\text{count}(\\text{word}_j, \\text{document}_i) $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow_vector(sentence: List[str]) -> np.ndarray:\n",
    "    vec = np.zeros(vocab_size)\n",
    "    word_count = Counter(sentence)\n",
    "    \n",
    "    for word, count in word_count.items():\n",
    "        if word in word2idx:\n",
    "            vec[word2idx[word]] = count\n",
    "\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_matrix = np.array([bow_vector(sentence) for sentence in tokenized_corpus])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 - Output and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm101",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
